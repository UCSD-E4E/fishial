{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbbd4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/fishial/Fishial/Object-Detection-Model')\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from module.classification_package.src.utils import read_json, save_json\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "# Change path specificly to your directories\n",
    "from torch import nn\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "from module.classification_package.src.dataset import FishialDatasetFoOnlineCuting\n",
    "from module.classification_package.src.utils import get_data_config, update_internal_id\n",
    "\n",
    "from module.classification_package.src.model import init_model\n",
    "from module.segmentation_package.src.utils import get_mask\n",
    "\n",
    "def get_config(path):\n",
    "    with open(path, \"r\") as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b569659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module,last_layer = 512, emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.embeddings = nn.Linear(last_layer, emb_dim)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.embeddings(self.backbone(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33134594",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([\n",
    "        transforms.Resize((224, 224), Image.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af525de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (embeddings): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_path = '/home/fishial/Fishial/output/classification/resnet_18_184_train_06_12'\n",
    "model_name= 'model_184.ckpt'\n",
    "device = 'cpu'\n",
    "resnet18 = models.resnet18()\n",
    "resnet18.fc = nn.Identity()\n",
    "\n",
    "model = EmbeddingModel(resnet18, 512, 256)\n",
    "model.load_state_dict(torch.load(os.path.join(absolute_path, model_name), map_location=torch.device(device)))\n",
    "model.eval()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "012fd778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo_dataset = fo.load_dataset(\"fish-classification-184\")\n",
    "fo_dataset = fo_dataset.match_tags(['val', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02d04f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: 30309/30310\r"
     ]
    }
   ],
   "source": [
    "list_numbers = random.choices([100,100], k=256) \n",
    "random_numbers = torch.Tensor(list_numbers)\n",
    "\n",
    "data_set_ids = {}\n",
    "embedding_tensor = []\n",
    "data_labels = {}\n",
    "for sample_id, sample in enumerate(fo_dataset):\n",
    "    print(f\"Left: {sample_id}/{len(fo_dataset)}\", end='\\r')\n",
    "    img_path = sample['filepath']\n",
    "    label = sample['polyline']['label']\n",
    "    image_id, annotation_id, drawn_fish_id = sample['image_id'], sample['annotation_id'], sample['drawn_fish_id']\n",
    "    width, height = sample['width'], sample['height']\n",
    "    \n",
    "    polyline = sample['polyline']['points'][0]\n",
    "    polyline = [[int(point[0] * width), int(point[1] * height)] for point in polyline]\n",
    "    \n",
    "    if label not in data_labels:\n",
    "        internal_id = str(len(data_labels))\n",
    "        data_labels.update({label :internal_id})\n",
    "        data_set_ids.update({internal_id: {\n",
    "            'image_id':[],\n",
    "            'annotation_id': [],\n",
    "            'drawn_fish_id': [],\n",
    "        }})\n",
    "        embedding_tensor.append([])\n",
    "    mask = cv2.imread(img_path)\n",
    "    mask = get_mask(mask, np.array(polyline))\n",
    "    mask = Image.fromarray(mask)\n",
    "    mask = loader(mask)\n",
    "    output = model(mask.unsqueeze(0))\n",
    "    embedding_tensor[int(data_labels[label])].append(output[0].detach())\n",
    "    \n",
    "    data_set_ids[data_labels[label]]['image_id'].append(image_id)\n",
    "    data_set_ids[data_labels[label]]['annotation_id'].append(annotation_id)\n",
    "    data_set_ids[data_labels[label]]['drawn_fish_id'].append(drawn_fish_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4798a36f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_val = max(len(i) for i in embedding_tensor)\n",
    "for i in range(len(embedding_tensor)):\n",
    "    if len(embedding_tensor[i]) < max_val:\n",
    "        for _ in range(max_val - len(embedding_tensor[i])):\n",
    "            embedding_tensor[i].append(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173c41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set = torch.stack ([torch.stack(i) for i in embedding_tensor] )\n",
    "torch.save(data_set, os.path.join(absolute_path, 'embeddings.pt'))\n",
    "data_labels = {data_labels[label]:label for label in data_labels}\n",
    "save_json(data_labels, os.path.join(absolute_path, 'labels.json'))\n",
    "save_json(data_set_ids, os.path.join(absolute_path, 'idx.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "005701a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=true&handleId=45630212-e0e0-4483-ab8b-f7164a39fa51\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f26c5b9e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset:     -\n",
       "Session URL: http://localhost:5151/"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ffd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2_env",
   "language": "python",
   "name": "detectron2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
